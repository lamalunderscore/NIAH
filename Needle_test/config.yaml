parent_dir: "NIAH/Needle_test"


prompt:
  save_dir: 'prompts'
  needle: "\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\n"
  haystack_dir: "PaulGrahamEssays"
  retrieval_question: "What is the best thing to do in San Francisco? Here is the most relevant sentence in the context:" # We use the Anthropic's retrieval question as the default one

  context:
    min_len: 250
    max_len: 4096
    interval: 10
    manually_select_list: null  # null or a list of context lengths to manually select

  document_depth:
    min_percent: 0
    max_percent: 100
    interval: 10
    interval_type: "linear"  # "linear", "sigmoid" or null
    manually_select_list: null  # null or a list of document percents to manually select

  tokenizer:
    tokenizer_type: "Huggingface" # "OpenAI", "Anthropic" or "Huggingface"
    model_name: "models/recurrent_gemma_default" # Change it to your own model name / HF model path


pred:
  save_dir: 'pred'
  sparsification:
    k: [10]
    metric: "l2"
    prefill: True
  # ckpt_path in notebook
  model_path: "/root/.cache/kagglehub/models/google/recurrentgemma/PyTorch/2b/1/2b.pt"

eval:
  save_dir: 'results'

vis:
  save_dir: 'vis'
